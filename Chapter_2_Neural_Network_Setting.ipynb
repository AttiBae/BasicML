{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter2 Simple Network with Linear layer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPr5IzDFaa1+WW3m8ZGqwjR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AttiBae/BasicML/blob/main/Chapter_2_Neural_Network_Setting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHA3I00AlRMM"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.autograd import Variable as variable\n",
        "dtype = torch.FloatTensor"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkL3iBcZqE0t"
      },
      "source": [
        "\n",
        "from torch.autograd import Variable as Variable"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKPJHBZvmVuO"
      },
      "source": [
        "def get_data():\n",
        "  train_x = np.asarray([1.1,2.2,3.3,4.4,5.5,6.6,7.7,8.8,9.9])\n",
        "  train_y = np.asarray([9.1,8.2,7.3,6.5,5.6,4.7,3.8,2.9,1.0])\n",
        "\n",
        "  X = Variable(torch.from_numpy(train_x).type(dtype), requires_grad = False)\n",
        "  Y = Variable(torch.from_numpy(train_y).type(dtype), requires_grad = False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-MYtMh0lj6K"
      },
      "source": [
        "def simple_net(x):\n",
        "  y = torch.matmul(x,w)+b\n",
        "  return y"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ki2TrqKl-HS"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "f = nn.Linear(9,1)  ## same as simple_net(x)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG3bcVO4mG9n"
      },
      "source": [
        "def loss_fn(y,y_pred):\n",
        "  loss = (y_pred-y).pow(2).sum() ## SSE(Sum of Squared) Loss\n",
        "  for param in [w,b]:\n",
        "    if not praram.grad is None:param,grad,data,zero_()\n",
        "  loss.backward()\n",
        "  return loss.data[0]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mfw6HI76vIS"
      },
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "loss = loss_fn(y_pred, y)\n",
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFgXk--HnGcr"
      },
      "source": [
        "def optimize(learning_rate):\n",
        "  w.data -= learning_rate * w.grad.data\n",
        "  b.data -= learning_rate * b.grad.data"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Dbo7WZ47ft6"
      },
      "source": [
        "for input, target in dataset:\n",
        "  optimizer.zero_grad()\n",
        "  output = model(input)\n",
        "  loss = loss_fn(output, target)\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI6NhDl8xntK"
      },
      "source": [
        "from torch.autograd import Variable as Variable\n",
        "from torch.nn import Linear\n",
        "\n",
        "input = Variable(torch.randn(1,10))\n",
        "\n",
        "L_Layer1 = Linear(10, 5)  ## Linear(in_features, out_features, bias=[True/False])\n",
        "L_Layer2 = Linear(5, 2)\n",
        "\n",
        "my_network = L_Layer2(L_Layer1(input))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoOMPcqbzWuz"
      },
      "source": [
        "L_Layer3 = Linear(10, 2)\n",
        "my_original_network = L_Layer3(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufd37xty3-vl",
        "outputId": "1eede7ce-3e2f-4dbc-8f0a-f5f0a7849193"
      },
      "source": [
        "sample = torch.Tensor([1,2,3,-3,-2,-1])\n",
        "\n",
        "ReLU = nn.ReLU()\n",
        "LReLU = nn.LeakyReLU()\n",
        "\n",
        "print('After ReLU : ', ReLU(sample))\n",
        "print('After Leaky ReLU : ',LReLU(sample))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After ReLU :  tensor([1., 2., 3., 0., 0., 0.])\n",
            "After Leaky ReLU :  tensor([ 1.0000,  2.0000,  3.0000, -0.0300, -0.0200, -0.0100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaoXyx4z5HOW"
      },
      "source": [
        "class myRealNetwork(nn.Module):\n",
        "  def __init__(self, input_size, hidden_sizae, output_size):\n",
        "    super(myRealNetwork, self).__init__()\n",
        "    self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "    self.layer2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, input):\n",
        "    out = self.layer1(input)\n",
        "    out = nn.ReLU(out)\n",
        "    out = self.layer2(out)\n",
        "    return out    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}